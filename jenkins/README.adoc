// Do not edit this file (e.g. go instead to docs/)
:jenkins-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/jenkins
:demo-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/demo
:concourse-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/concourse
:intro-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/intro
== Jenkins Pipeline (Common)

In this section we will present the common setup of Jenkins for any platform.
We will also provide answers to most frequently asked questions.

=== Project setup

[source,bash]
----
.
├── declarative-pipeline
│   └── Jenkinsfile-sample.groovy
├── jobs
│   ├── jenkins_pipeline_empty.groovy
│   ├── jenkins_pipeline_jenkinsfile_empty.groovy
│   ├── jenkins_pipeline_sample.groovy
│   └── jenkins_pipeline_sample_view.groovy
├── seed
│   ├── init.groovy
│   ├── jenkins_pipeline.groovy
│   ├── k8s
│   └── settings.xml
└── src
    ├── main
    └── test
----

In the `declarative-pipeline` you can find a definition of a `Jenkinsfile-sample.groovy` declarative
pipeline. It's used together with the Blueocean UI.

In the `jobs` folder you have all the seed jobs that will generate pipelines.

- `jenkins_pipeline_empty.groovy` - is a template of a pipeline with empty steps using the Jenkins Job DSL plugin
- `jenkins_pipeline_jenkinsfile_empty.groovy` - is a template of a pipeline with empty steps using the Pipeline plugin
- `jenkins_pipeline_sample.groovy` - is an opinionated implementation using the Jenkins Job DSL plugin
- `jenkins_pipeline_sample_view.groovy` - builds the views for the pipelines

In the `seed` folder you have the `init.groovy` file which is executed when Jenkins starts.
That way we can configure most of Jenkins options for you (adding credentials, JDK etc.).
`jenkins_pipeline.groovy` contains logic to build a seed job (that way you don't have to even click that
job - we generate it for you). Under the `k8s` folder there are all the configuration
files required for deployment to a Kubernetes cluster.

In the `src` folder you have production and test classes needed for you to build your own pipeline.
Currently we have tests only cause the whole logic resides in the `jenkins_pipeline_sample` file.

=== Optional customization steps

[[jenkins_optional]] All the steps below are not necessary to run the demo. They are needed only
when you want to do some custom changes.

[[deploying-infra]]
==== Deploying infra jars to a different location

It's enough to set the `ARTIFACTORY_URL` environmental variable before
executing `tools/deploy-infra.sh`. Example for deploying to Artifactory at IP `192.168.99.100`

[source,bash]
----
git clone https://github.com/spring-cloud/spring-cloud-pipelines
cd spring-cloud-pipelines/
ARTIFACTORY_URL="http://192.168.99.100:8081/artifactory/libs-release-local" ./tools/deploy-infra.sh
----

[[setup-settings-xml]]
==== Setup settings.xml for Maven deployment

TIP: If you want to use the default connection to the Docker version
of Artifactory you can skip this step

[[jenkins-settings]] So that `./mvnw deploy` works with Artifactory from Docker we're
already copying the missing `settings.xml` file for you. It looks more or less like this:

[source,xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<settings>
	<servers>
		<server>
			<id>${M2_SETTINGS_REPO_ID}</id>
			<username>${M2_SETTINGS_REPO_USERNAME}</username>
			<password>${M2_SETTINGS_REPO_PASSWORD}</password>
		</server>
		<server>
			<id>${DOCKER_SERVER_ID}</id>
			<username>${DOCKER_USERNAME}</username>
			<password>${DOCKER_PASSWORD}</password>
			<configuration>
				<email>${DOCKER_EMAIL}</email>
			</configuration>
		</server>
	</servers>
</settings>
----

As you can see the file is parameterized. In Maven it's enough to pass
to `./mvnw` command the proper system property to override that value. For example to pass
a different docker email you'd have to call `./mvnw -DDOCKER_EMAIL=foo@bar.com` and the value
gets updated.

If you want to use your own version of Artifactory / Nexus you have to update
the file (it's in `seed/settings.xml`).

[[setup-jenkins-env-vars]]
==== Setup Jenkins env vars

[[jenkins_env]] If you want to only play around with the demo that we've prepared you have to set *ONE* variable which is the `REPOS` variable.
That variable needs to consists of comma separated list of URLs to repositories containing business apps. So you should pass your forked repos URLs.

You can do it in the following ways:

- globally via Jenkins global env vars (then when you run the seed that variable will be taken into consideration and proper pipelines will get built)
- modify the seed job parameters (you'll have to modify the seed job configuration and change the `REPOS` property)
- provide the repos parameter when running the seed job

For the sake of simplicity let's go with the *last* option.

IMPORTANT: If you're choosing the global envs, you *HAVE* to remove the other approach
(e.g. if you set the global env for `REPOS`, please remove that property in the
seed job

[[setup-seed-props]]
===== Seed properties

Click on the seed job and pick `Build with parameters`. Then as presented in the screen below (you'll have far more properties to set) just modify the `REPOS` property by providing the comma separated list of URLs to your forks. Whatever you set will be parsed by the seed job and passed to the generated Jenkins jobs.

TIP: This is very useful when the repos you want to build differ. E.g. use
different JDK. Then some seeds can set the `JDK_VERSION` param to one version
of Java installation and the others to another one.

Example screen:

image::{jenkins-root-docs}/seed.png[]

In the screenshot we could parametrize the `REPOS` and `REPO_WITH_BINARIES` params.

[[global-envs]]
===== Global envs

IMPORTANT: This section is presented only for informational purposes - for the sake of demo you can skip it

You can add env vars (go to configure Jenkins -> Global Properties) for the following
 properties (example with defaults for PCF Dev):

Example screen:

image::{jenkins-root-docs}/env_vars.png[]

[[git-email]]
==== Set Git email / user

Since our pipeline is setting the git user / name explicitly for the build step
 you'd have to go to `Configure` of the build step and modify the Git name / email.
 If you want to set it globally you'll have to remove the section from the build
 step and follow these steps to set it globally.

You can set Git email / user globally like this:

{nbsp}
{nbsp}

image::{jenkins-root-docs}/manage_jenkins.png[caption="Step 1: ", title="Click 'Manage Jenkins'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/configure_system.png[caption="Step 2: ", title="Click 'Configure System'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/git.png[caption="Step 3: ", title="Fill out Git user information"]

{nbsp}
{nbsp}


[[jenkins-credentials-github]]
===== Add Jenkins credentials for GitHub

[[jenkins-credentials]] The scripts will need to access the credential in order to tag the repo.

You have to set credentials with id: `git`.

Below you can find instructions on how to set a credential (e.g. for Cloud Foundry `cf-test` credential but
remember to provide the one with id `git`).

{nbsp}
{nbsp}

image::{jenkins-root-docs}/credentials_system.png[caption="Step 1: ", title="Click 'Credentials, System'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/credentials_global.png[caption="Step 2: ", title="Click 'Global Credentials'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/credentials_add.png[caption="Step 3: ", title="Click 'Add credentials'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/credentials_example.png[caption="Step 4: ", title="Fill out the user / password and provide the `git` credential ID (in this example `cf-test`)"]

{nbsp}
{nbsp}

=== Testing Jenkins scripts

`./gradlew clean build`

WARNING: The ran test only checks if your scripts compile.

=== How to work with Jenkins Job DSL plugin

Check out the https://github.com/jenkinsci/job-dsl-plugin/wiki/Tutorial---Using-the-Jenkins-Job-DSL[tutorial].
Provide the link to this repository in your Jenkins installation.

WARNING: Remember that views can be overridden that's why the suggestion is to contain in one script all the logic needed to build a view
 for a single project (check out that `spring_cloud_views.groovy` is building all the `spring-cloud` views).

=== Docker Image

If you would like to run the pre-configured Jenkins image somewhere other than your local machine, we
have an image you can pull and use on https://hub.docker.com/r/springcloud/spring-cloud-pipeline-jenkins/[DockerHub].
The `latest` tag corresponds to the latest snapshot build.  You can also find tags
corresponding to stable releases that you can use as well.

// remove::start[CF]
[[jenkins-pipeline-cf]]
== Jenkins Pipeline (Cloud Foundry)

IMPORTANT: In this chapter we assume that you perform deployment of your application
to Cloud Foundry PaaS

[[jenkins]] The Spring Cloud Pipelines repository contains job definitions and the opinionated setup pipeline using https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin[Jenkins Job DSL plugin]. Those jobs will form an empty pipeline and a sample, opinionated one that you can use in your company.

All in all there are the following projects taking part in the whole `microservice setup` for this demo.

- https://github.com/spring-cloud-samples/github-analytics[Github Analytics] - the app that has a REST endpoint and uses messaging. Our business application.
- https://github.com/spring-cloud-samples/github-webhook[Github Webhook] - project that emits messages that are used by Github Analytics. Our business application.
- https://github.com/spring-cloud-samples/github-eureka[Eureka] - simple Eureka Server. This is an infrastructure application.
- https://github.com/spring-cloud-samples/github-analytics-stub-runner-boot[Github Analytics Stub Runner Boot] - Stub Runner Boot server to be used for tests with Github Analytics. Uses Eureka and Messaging. This is an infrastructure application.

[[step-by-step-cf]]
=== Step by step

This is a guide for Jenkins Job DSL based pipeline.

If you want to just run the demo as far as possible using PCF Dev and Docker Compose

- <<jenkins-fork-cf,Fork repos>>
- <<jenkins-start-cf,Start Jenkins and Artifactory>>
- <<jenkins-deploy-cf,Deploy infra to Artifactory>>
- <<jenkins-pcfdev-cf,Start PCF Dev (if you don't want to use an existing one)>>
- <<jenkins-seed-cf,Run the seed job>>
- <<jenkins-pipeline-cf,Run the `github-webhook` pipeline>>

[[fork-repos-cf]]
==== Fork repos

[[jenkins-fork-cf]] There are 4 apps that are composing the pipeline

  - https://github.com/spring-cloud-samples/github-webhook[Github Webhook]
  - https://github.com/spring-cloud-samples/github-analytics/[Github Analytics]
  - https://github.com/spring-cloud-samples/github-eureka[Github Eureka]
  - https://github.com/spring-cloud-samples/github-analytics-stub-runner-boot[Github Stub Runner Boot]

You need to fork only these. That's because only then will your user be able to tag and push the tag to repo.

  - https://github.com/spring-cloud-samples/github-webhook[Github Webhook]
  - https://github.com/spring-cloud-samples/github-analytics/[Github Analytics]

[[start-jenkins-cf]]
==== Start Jenkins and Artifactory

[[jenkins-start-cf]] Jenkins + Artifactory can be ran locally. To do that just execute the
`start.sh` script from this repo.

[source,bash]
----
git clone https://github.com/spring-cloud/spring-cloud-pipelines
cd spring-cloud-pipelines/jenkins
./start.sh yourGitUsername yourGitPassword yourForkedGithubOrg
----
Then Jenkins will be running on port `8080` and Artifactory `8081`.
The provided parameters will be passed as env variables to Jenkins VM
and credentials will be set in your set. That way you don't have to do
any manual work on the Jenkins side. In the above parameters, the third parameter
could be yourForkedGithubOrg or yourGithubUsername. Also the `REPOS` env variable will
contain your GitHub org in which you have the forked repos.

[[deploy-infra-cf]]
===== Deploy the infra JARs to Artifactory

[[jenkins-deploy-cf]] When Artifactory is running, just execute the `tools/deploy-infra.sh` script from this repo.

[source,bash]
----
git clone https://github.com/spring-cloud/spring-cloud-pipelines
cd spring-cloud-pipelines/
./tools/deploy-infra.sh
----

As a result both `eureka` and `stub runner` repos will be cloned, built
and uploaded to Artifactory.

[[start-pcf-dev-cf]]
==== Start PCF Dev

TIP: You can skip this step if you have CF installed and don't want to use PCF Dev
The only thing you have to do is to set up spaces.

WARNING: It's more than likely that you'll run out of resources when you reach stage step.
Don't worry! Keep calm and <<jenkins-cf-resources,clear some apps from PCF Dev and continue>>.

[[jenkins-pcfdev-cf]] You have to download and start PCF Dev. https://pivotal.io/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/install-pcf-dev[A link how to do it is available here.]

The default credentials when using PCF Dev are:

[source,bash]
----
username: user
password: pass
email: user
org: pcfdev-org
space: pcfdev-space
api: api.local.pcfdev.io
----

You can start the PCF Dev like this:

[source,bash]
----
cf dev start
----

You'll have to create 3 separate spaces (email admin, pass admin)

[source,bash]
----
cf login -a https://api.local.pcfdev.io --skip-ssl-validation -u admin -p admin -o pcfdev-org

cf create-space pcfdev-test
cf set-space-role user pcfdev-org pcfdev-test SpaceDeveloper
cf create-space pcfdev-stage
cf set-space-role user pcfdev-org pcfdev-stage SpaceDeveloper
cf create-space pcfdev-prod
cf set-space-role user pcfdev-org pcfdev-prod SpaceDeveloper
----

You can also execute the `./tools/cf-helper.sh setup-spaces` to do this.

[[jenkins-seed-cf]]
==== Run the seed job

We already create the seed job for you but you'll have to run it. When you do
run it you have to provide some properties. By default we create a seed that
has all the properties options, but you can delete most of it. If you
set the properties as global env variables you have to remove them from the
seed.

Anyways, to run the demo just provide in the `REPOS` var the comma separated
 list of URLs of the 2 aforementioned forks of `github-webhook` and `github-analytics'.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_click.png[caption="Step 1: ", title="Click the 'jenkins-pipeline-seed-cf' job for Cloud Foundry and `jenkins-pipeline-seed-k8s` for Kubernetes"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_run.png[caption="Step 2: ", title="Click the 'Build with parameters'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed.png[caption="Step 3: ", title="The `REPOS` parameter should already contain your forked repos (you'll have more properties than the ones in the screenshot)"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_built.png[caption="Step 4: ", title="This is how the results of seed should look like"]

[[jenkins-pipeline-cf]]
==== Run the `github-webhook` pipeline

We already create the seed job for you but you'll have to run it. When you do
run it you have to provide some properties. By default we create a seed that
has all the properties options, but you can delete most of it. If you
set the properties as global env variables you have to remove them from the
seed.

Anyways, to run the demo just provide in the `REPOS` var the comma separated
 list of URLs of the 2 aforementioned forks of `github-webhook` and `github-analytics`.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_views.png[caption="Step 1: ", title="Click the 'github-webhook' view"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_run.png[caption="Step 2: ", title="Run the pipeline"]

{nbsp}
{nbsp}

IMPORTANT: If your build fails on the *deploy previous version to stage* due to missing jar,
that means that you've forgotten to clear the tags in your repo. Typically that's due to the fact that
you've removed the Artifactory volume with deployed JAR whereas a tag in the repo is still pointing there.
<<tags,Check out this section on how to remove the tag.>>

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_manual.png[caption="Step 3: ", title="Click the manual step to go to stage (remember about killing the apps on test env). To do this click the *ARROW* next to the job name"]

{nbsp}
{nbsp}

IMPORTANT: Most likely you will run out of memory so when reaching the stage
environment it's good to kill all apps on test. <<faq,Check out the FAQ section for more details>>!

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_finished.png[caption="Step 4: ", title="The full pipeline should look like this"]

{nbsp}
{nbsp}

[[declarative-pipeline-cf]]
=== Declarative pipeline & Blue Ocean

You can also use the https://jenkins.io/doc/book/pipeline/syntax/[declarative pipeline] approach with the
https://jenkins.io/projects/blueocean/[Blue Ocean UI]. Here is a step by step guide to run a pipeline via
this approach.

The Blue Ocean UI is available under the `blue/` URL. E.g. for Docker Machine based setup `http://192.168.99.100:8080/blue`.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_1.png[caption="Step 1: ", title="Open Blue Ocean UI and click on `github-webhook-declarative-pipeline`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_2.png[caption="Step 2: ", title="Your first run will look like this. Click `Run` button"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_3.png[caption="Step 3: ", title="Enter parameters required for the build and click `run`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_4.png[caption="Step 4: ", title="A list of pipelines will be shown. Click your first run."]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_5.png[caption="Step 5: ", title="State if you want to go to production or not and click `Proceed`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_6.png[caption="Step 6: ", title="The build is in progress..."]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_7.png[caption="Step 7: ", title="The pipeline is done!"]

{nbsp}
{nbsp}


IMPORTANT: There is no possibility of restarting pipeline from specific stage, after failure. Please
check out this https://issues.jenkins-ci.org/browse/JENKINS-33846[issue] for more information

WARNING: Currently there is no way to introduce manual steps in a performant way. Jenkins is
blocking an executor when manual step is required. That means that you'll run out of executors
pretty fast. You can check out this https://issues.jenkins-ci.org/browse/JENKINS-36235[issue] for
and this http://stackoverflow.com/questions/42561241/how-to-wait-for-user-input-in-a-declarative-pipeline-without-blocking-a-heavywei[StackOverflow question]
for more information.

[[optional-steps-cf]]
=== Jenkins Cloud Foundry customization

 All the steps below are not necessary to run the demo. They are needed only
when you want to do some custom changes.

[[all-env-vars-cf]]
==== All env vars

The env vars that are used in all of the jobs are as follows:

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|PAAS_TEST_API_URL | The URL to the CF Api for TEST env| api.local.pcfdev.io
|PAAS_STAGE_API_URL | The URL to the CF Api for STAGE env | api.local.pcfdev.io
|PAAS_PROD_API_URL | The URL to the CF Api for PROD env | api.local.pcfdev.io
|PAAS_TEST_ORG    | Name of the org for the test env | pcfdev-org
|PAAS_TEST_SPACE_PREFIX  | Prefix of the name of the CF space for the test env to which the app name will be appended | sc-pipelines-test
|PAAS_STAGE_ORG   | Name of the org for the stage env | pcfdev-org
|PAAS_STAGE_SPACE | Name of the space for the stage env | sc-pipelines-stage
|PAAS_PROD_ORG   | Name of the org for the prod env | pcfdev-org
|PAAS_PROD_SPACE | Name of the space for the prod env | sc-pipelines-prod
|REPO_WITH_BINARIES_FOR_UPLOAD | URL to repo with the deployed jars | http://artifactory:8081/artifactory/libs-release-local
|M2_SETTINGS_REPO_ID | The id of server from Maven settings.xml | artifactory-local
|JDK_VERSION | The name of the JDK installation | jdk8
|PIPELINE_VERSION | What should be the version of the pipeline (ultimately also version of the jar) | 1.0.0.M1-${GROOVY,script ="new Date().format('yyMMdd_HHmmss')"}-VERSION
|GIT_EMAIL | The email used by Git to tag repo | email@example.com
|GIT_NAME | The name used by Git to tag repo | Pivo Tal
|PAAS_HOSTNAME_UUID | Additional suffix for the route. In a shared environment the default routes can be already taken |
|AUTO_DEPLOY_TO_STAGE | Should deployment to stage be automatic | false
|AUTO_DEPLOY_TO_PROD | Should deployment to prod be automatic | false
|API_COMPATIBILITY_STEP_REQUIRED | Should api compatibility step be required | true
|DB_ROLLBACK_STEP_REQUIRED | Should DB rollback step be present | true
|DEPLOY_TO_STAGE_STEP_REQUIRED | Should deploy to stage step be present | true
|JAVA_BUILDPACK_URL | The URL to the Java buildpack to be used by CF | https://github.com/cloudfoundry/java-buildpack.git#v3.8.1 |
|BUILD_OPTIONS | Additional options you would like to pass to the Maven / Gradle build |
|BINARY_EXTENSION | Extension of the binary uploaded to Artifactory / Nexus. Example: change this to `war` for WAR artifacts | jar
|======================

[[jenkins-credentials-cf]]
==== Jenkins Credentials

In your scripts we reference the credentials via IDs. These are the defaults for credentials

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|GIT_CREDENTIAL_ID    | Credential ID used to tag a git repo | git
|GIT_SSH_CREDENTIAL_ID    | SSH credential ID used to tag a git repo | gitSsh
|GIT_USE_SSH_KEY    | if `true` will pick to use the SSH credential id | false
|REPO_WITH_BINARIES_CREDENTIAL_ID    | Credential ID used for the repo with jars | repo-with-binaries
|PAAS_TEST_CREDENTIAL_ID  | Credential ID for CF Test env access | cf-test
|PAAS_STAGE_CREDENTIAL_ID   | Credential ID for CF Stage env access | cf-stage
|PAAS_PROD_CREDENTIAL_ID | Credential ID for CF Prod env access | cf-prod
|======================

If you already have in your system a credential to for example tag a repo
you can use it by passing the value of the property `GIT_CREDENTIAL_ID`

TIP: Check out the `cf-helper` script for all the configuration options!
// remove::end[CF]

// remove::start[K8S]
[[jenkins-pipeline-k8s]]
== Jenkins Pipeline (Kubernetes)

IMPORTANT: In this chapter we assume that you perform deployment of your application
to Kubernetes PaaS

[[jenkins]] The Spring Cloud Pipelines repository contains job definitions and the opinionated setup pipeline using https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin[Jenkins Job DSL plugin]. Those jobs will form an empty pipeline and a sample, opinionated one that you can use in your company.

All in all there are the following projects taking part in the whole `microservice setup` for this demo.

- https://github.com/spring-cloud-samples/github-analytics-kubernetes[Github Analytics] - the app that has a REST endpoint and uses messaging. Our business application.
- https://github.com/spring-cloud-samples/github-webhook-kubernetes[Github Webhook] - project that emits messages that are used by Github Analytics. Our business application.
- https://github.com/spring-cloud-samples/github-eureka[Eureka] - simple Eureka Server. This is an infrastructure application.
- https://github.com/spring-cloud-samples/github-analytics-stub-runner-boot[Github Analytics Stub Runner Boot] - Stub Runner Boot server to be used for tests with Github Analytics. Uses Eureka and Messaging. This is an infrastructure application.

[[step-by-step-k8s]]
=== Step by step

This is a guide for Jenkins Job DSL based pipeline.

If you want to just run the demo as far as possible using PCF Dev and Docker Compose

- <<jenkins-fork-k8s,Fork repos>>
- <<jenkins-start-k8s,Start Jenkins and Artifactory>>
- <<jenkins-deploy-k8s,Deploy infra to Artifactory>>
- <<jenkins-minikube-k8s,Start Minikube (if you don't want to use an existing one)>>
- <<jenkins-seed-k8s,Run the seed job>>
- <<jenkins-pipeline-k8s,Run the `github-webhook` pipeline>>

[[fork-repos-k8s]]
==== Fork repos

[[jenkins-fork-k8s]] There are 4 apps that are composing the pipeline

  - https://github.com/spring-cloud-samples/github-webhook-kubernetes[Github Webhook]
  - https://github.com/spring-cloud-samples/github-analytics-kubernetes/[Github Analytics]
  - https://github.com/spring-cloud-samples/github-eureka[Github Eureka]
  - https://github.com/spring-cloud-samples/github-analytics-stub-runner-boot-classpath-stubs[Github Stub Runner Boot]

You need to fork only these. That's because only then will your user be able to tag and push the tag to repo.

  - https://github.com/spring-cloud-samples/github-webhook-kubernetes[Github Webhook]
  - https://github.com/spring-cloud-samples/github-analytics-kubernetes/[Github Analytics]

[[start-jenkins-k8s]]
==== Start Jenkins and Artifactory

[[jenkins-start-k8s]] Jenkins + Artifactory can be ran locally. To do that just execute the
`start.sh` script from this repo.

[source,bash]
----
git clone https://github.com/spring-cloud/spring-cloud-pipelines
cd spring-cloud-pipelines/jenkins
./start.sh yourGitUsername yourGitPassword yourForkedGithubOrg yourDockerRegistryOrganization yourDockerRegistryUsername yourDockerRegistryPassword yourDockerRegistryEmail
----
Then Jenkins will be running on port `8080` and Artifactory `8081`.
The provided parameters will be passed as env variables to Jenkins VM
and credentials will be set in your set. That way you don't have to do
any manual work on the Jenkins side. In the above parameters, the third parameter
could be yourForkedGithubOrg or yourGithubUsername. Also the `REPOS` env variable will
contain your GitHub org in which you have the forked repos.

You need to pass the credentials for the Docker organization (by default we will
search for the Docker images at Docker Hub) so that the pipeline will be able
to push images to your org.

[[deploy-infra-k8s]]
===== Deploy the infra JARs to Artifactory

[[jenkins-deploy-k8s]] When Artifactory is running, just execute the `tools/deploy-infra.sh` script from this repo.

[source,bash]
----
git clone https://github.com/spring-cloud/spring-cloud-pipelines
cd spring-cloud-pipelines/
./tools/deploy-infra-k8s.sh
----

As a result both `eureka` and `stub runner` repos will be cloned, built,
uploaded to Artifactory and their docker images will be built.

IMPORTANT: Your local Docker process will be reused by the Jenkins instance running
in Docker. That's why you don't have to push these images to Docker Hub. On the
other hand if you run this sample in a remote Kubernetes cluster the driver
will not be shared by the Jenkins workers so you can consider pushing these
Docker images to Docker Hub too.

[[jenkins-seed-k8s]]
==== Run the seed job

We already create the seed job for you but you'll have to run it. When you do
run it you have to provide some properties. By default we create a seed that
has all the properties options, but you can delete most of it. If you
set the properties as global env variables you have to remove them from the
seed.

Anyways, to run the demo just provide in the `REPOS` var the comma separated
 list of URLs of the 2 aforementioned forks of `github-webhook` and `github-analytics'.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_click.png[caption="Step 1: ", title="Click the 'jenkins-pipeline-seed-cf' job for Cloud Foundry and `jenkins-pipeline-seed-k8s` for Kubernetes"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_run.png[caption="Step 2: ", title="Click the 'Build with parameters'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed.png[caption="Step 3: ", title="The `REPOS` parameter should already contain your forked repos (you'll have more properties than the ones in the screenshot)"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_built.png[caption="Step 4: ", title="This is how the results of seed should look like"]

[[jenkins-pipeline-k8s]]
==== Run the `github-webhook` pipeline

We already create the seed job for you but you'll have to run it. When you do
run it you have to provide some properties. By default we create a seed that
has all the properties options, but you can delete most of it. If you
set the properties as global env variables you have to remove them from the
seed.

Anyways, to run the demo just provide in the `REPOS` var the comma separated
 list of URLs of the 2 aforementioned forks of `github-webhook` and `github-analytics`.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/seed_views.png[caption="Step 1: ", title="Click the 'github-webhook' view"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_run.png[caption="Step 2: ", title="Run the pipeline"]

{nbsp}
{nbsp}

IMPORTANT: If your build fails on the *deploy previous version to stage* due to missing jar,
that means that you've forgotten to clear the tags in your repo. Typically that's due to the fact that
you've removed the Artifactory volume with deployed JAR whereas a tag in the repo is still pointing there.
<<tags,Check out this section on how to remove the tag.>>

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_manual.png[caption="Step 3: ", title="Click the manual step to go to stage (remember about killing the apps on test env). To do this click the *ARROW* next to the job name"]

{nbsp}
{nbsp}

IMPORTANT: Most likely you will run out of memory so when reaching the stage
environment it's good to kill all apps on test. <<faq,Check out the FAQ section for more details>>!

{nbsp}
{nbsp}

image::{jenkins-root-docs}/pipeline_finished.png[caption="Step 4: ", title="The full pipeline should look like this"]

{nbsp}
{nbsp}

[[declarative-pipeline-k8s]]
=== Declarative pipeline & Blue Ocean

You can also use the https://jenkins.io/doc/book/pipeline/syntax/[declarative pipeline] approach with the
https://jenkins.io/projects/blueocean/[Blue Ocean UI]. Here is a step by step guide to run a pipeline via
this approach.

The Blue Ocean UI is available under the `blue/` URL. E.g. for Docker Machine based setup `http://192.168.99.100:8080/blue`.

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_1.png[caption="Step 1: ", title="Open Blue Ocean UI and click on `github-webhook-declarative-pipeline`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_2.png[caption="Step 2: ", title="Your first run will look like this. Click `Run` button"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_3.png[caption="Step 3: ", title="Enter parameters required for the build and click `run`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_4.png[caption="Step 4: ", title="A list of pipelines will be shown. Click your first run."]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_5.png[caption="Step 5: ", title="State if you want to go to production or not and click `Proceed`"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_6.png[caption="Step 6: ", title="The build is in progress..."]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/blue_7.png[caption="Step 7: ", title="The pipeline is done!"]

{nbsp}
{nbsp}


IMPORTANT: There is no possibility of restarting pipeline from specific stage, after failure. Please
check out this https://issues.jenkins-ci.org/browse/JENKINS-33846[issue] for more information

WARNING: Currently there is no way to introduce manual steps in a performant way. Jenkins is
blocking an executor when manual step is required. That means that you'll run out of executors
pretty fast. You can check out this https://issues.jenkins-ci.org/browse/JENKINS-36235[issue] for
and this http://stackoverflow.com/questions/42561241/how-to-wait-for-user-input-in-a-declarative-pipeline-without-blocking-a-heavywei[StackOverflow question]
for more information.

[[optional-steps-k8s]]
=== Jenkins Kubernetes customization

IMPORTANT: All the steps below are not necessary to run the demo. They are needed only
when you want to do some custom changes.

[[all-env-vars-k8s]]
==== All env vars

The env vars that are used in all of the jobs are as follows:

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|DOCKER_REGISTRY_ORGANIZATION | Name of the docker organization to which Docker images should be deployed | scpipelines
|DOCKER_REGISTRY_CREDENTIAL_ID | Credential ID used to push Docker images | docker-registry
|DOCKER_SERVER_ID | Server ID in `settings.xml` and Maven builds | docker-repo
|DOCKER_EMAIL | Email used to connect to Docker registry` and Maven builds | change@me.com
|DOCKER_REGISTRY_ORGANIZATION | URL to Kubernetes cluster for test env | scpipelines
|DOCKER_REGISTRY_URL | URL to the docker registry | https://index.docker.io/v1/
|PAAS_TEST_API_URL | URL of the API of the Kubernetes cluster for test environment | 192.168.99.100:8443
|PAAS_STAGE_API_URL | URL of the API of the Kubernetes cluster for stage environment  | 192.168.99.100:8443
|PAAS_PROD_API_URL | URL of the API of the Kubernetes cluster for prod environment | 192.168.99.100:8443
|PAAS_TEST_CA_PATH | Path to the certificate authority for test environment | /usr/share/jenkins/cert/ca.crt
|PAAS_STAGE_CA_PATH | Path to the certificate authority for stage environment | /usr/share/jenkins/cert/ca.crt
|PAAS_PROD_CA_PATH | Path to the certificate authority for prod environment | /usr/share/jenkins/cert/ca.crt
|PAAS_TEST_CLIENT_CERT_PATH | Path to the client certificate for test environment | /usr/share/jenkins/cert/apiserver.crt
|PAAS_STAGE_CLIENT_CERT_PATH | Path to the client certificate for stage environment | /usr/share/jenkins/cert/apiserver.crt
|PAAS_PROD_CLIENT_CERT_PATH | Path to the client certificate for prod environment | /usr/share/jenkins/cert/apiserver.crt
|PAAS_TEST_CLIENT_KEY_PATH | Path to the client key for test environment | /usr/share/jenkins/cert/apiserver.key
|PAAS_STAGE_CLIENT_KEY_PATH | Path to the client key for stage environment | /usr/share/jenkins/cert/apiserver.key
|PAAS_PROD_CLIENT_KEY_PATH | Path to the client key for test environment | /usr/share/jenkins/cert/apiserver.key
|PAAS_TEST_CLIENT_TOKEN_PATH | Path to the file containing the token for test env |
|PAAS_STAGE_CLIENT_TOKEN_PATH | Path to the file containing the token for stage env |
|PAAS_PROD_CLIENT_TOKEN_PATH | Path to the file containing the token for prod env |
|PAAS_TEST_CLIENT_TOKEN_ID | ID of the credential containing access token for test environment |
|PAAS_STAGE_CLIENT_TOKEN_ID | ID of the credential containing access token for stage environment |
|PAAS_PROD_CLIENT_TOKEN_ID | ID of the credential containing access token for prod environment |
|PAAS_TEST_CLUSTER_NAME | Name of the cluster for test environment | minikube
|PAAS_STAGE_CLUSTER_NAME | Name of the cluster for stage environment | minikube
|PAAS_PROD_CLUSTER_NAME | Name of the cluster for prod environment | minikube
|PAAS_TEST_CLUSTER_USERNAME | Name of the user for test environment | minikube
|PAAS_STAGE_CLUSTER_USERNAME | Name of the user for stage environment | minikube
|PAAS_PROD_CLUSTER_USERNAME | Name of the user for prod environment | minikube
|PAAS_TEST_SYSTEM_NAME | Name of the system for test environment | minikube
|PAAS_STAGE_SYSTEM_NAME | Name of the system for stage environment | minikube
|PAAS_PROD_SYSTEM_NAME | Name of the system for prod environment | minikube
|PAAS_TEST_NAMESPACE | Namespace for test environment | sc-pipelines-test
|PAAS_STAGE_NAMESPACE | Namespace for stage environment | sc-pipelines-stage
|PAAS_PROD_NAMESPACE | Namespace for prod environment | sc-pipelines-prod
|KUBERNETES_MINIKUBE | Will you connect to Minikube? | true
|REPO_WITH_BINARIES_FOR_UPLOAD | URL to repo with the deployed jars | http://artifactory:8081/artifactory/libs-release-local
|REPO_WITH_BINARIES_CREDENTIAL_ID    | Credential ID used for the repo with jars | repo-with-binaries
|M2_SETTINGS_REPO_ID | The id of server from Maven settings.xml | artifactory-local
|JDK_VERSION | The name of the JDK installation | jdk8
|PIPELINE_VERSION | What should be the version of the pipeline (ultimately also version of the jar) | 1.0.0.M1-${GROOVY,script ="new Date().format('yyMMdd_HHmmss')"}-VERSION
|GIT_EMAIL | The email used by Git to tag repo | email@example.com
|GIT_NAME | The name used by Git to tag repo | Pivo Tal
|AUTO_DEPLOY_TO_STAGE | Should deployment to stage be automatic | false
|AUTO_DEPLOY_TO_PROD | Should deployment to prod be automatic | false
|API_COMPATIBILITY_STEP_REQUIRED | Should api compatibility step be required | true
|DB_ROLLBACK_STEP_REQUIRED | Should DB rollback step be present | true
|DEPLOY_TO_STAGE_STEP_REQUIRED | Should deploy to stage step be present | true
|BUILD_OPTIONS | Additional options you would like to pass to the Maven / Gradle build |
|======================

=== Preparing to connect to GCE

IMPORTANT: Skip this step if you're not using GCE

In order to use GCE we need to have `gcloud` running. If you already have the
CLI installed, skip this step. If not just execute to have the CLI
downloaded and an installer started

```bash
$ ./tools/k8s-helper.sh download-gcloud
```

Next, configure `gcloud`. Execute `gcloud init` and log in
to your cluster. You will get redirected to a login page, pick the
proper Google account and log in.

Pick an existing project or create a new one.

Go to your platform page (click on `Container Engine`) in GCP and connect to your cluster

```bash
$ CLUSTER_NAME=...
$ ZONE=us-east1-b
$ PROJECT_NAME=...
$ gcloud container clusters get-credentials ${CLUSTER_NAME} --zone ${ZONE} --project ${PROJECT_NAME}
$ kubectl proxy
```

The Kubernetes dashboard will be running at `http://localhost:8001/ui/`.

We'll need a Persistent Disk for our Jenkins installation. Let's create it

```bash
$ ZONE=us-east1-b
$ gcloud compute disks create --size=200GB --zone=${ZONE} sc-pipelines-jenkins-disk
```

Since the disk got created now we need to format it. You can check out
the instructions on how to do it here - https://cloud.google.com/compute/docs/disks/add-persistent-disk#formatting

=== Connecting to a Kubo or GCE cluster

IMPORTANT: Skip this step if you're not using Kubo or GCE

In this section a description of steps required to deploy Jenkins and
Artifactory to a Kubernetes cluster deployed via Kubo.

TIP: To see the dashboard just do `kubectl proxy` and access `localhost:8081/ui`

- Log in to the cluster
- Deploy Jenkins and Artifactory to the cluster
* `./tools/k8s-helper.sh setup-tools-infra-vsphere` for a cluster deployed on VSphere
* `./tools/k8s-helper.sh setup-tools-infra-gce` for a cluster deployed to GCE
- Forward the ports so that you can access the Jenkins UI from your local machine

```bash
$ NAMESPACE=default
$ JENKINS_POD=jenkins-1430785859-nfhx4
$ LOCAL_PORT=32044
$ CONTAINER_PORT=8080
$ kubectl port-forward --namespace=${NAMESPACE} ${JENKINS_POD} ${LOCAL_PORT}:${CONTAINER_PORT}
```
- Go to `Credentials`, click `System` and `Global credentials`

image::{jenkins-root-docs}/kubo_credentials.png[caption="Click `Global credentials`"]

- Update `git`, `repo-with-binaries` and `docker-registry` credentials
- Run the `jenkins-pipeline-k8s-seed` seed job and fill it out with the following data
* Put `kubernetes.default:443` here (or `KUBERNETES_API:KUBERNETES_PORT`)
** `PAAS_TEST_API_URL`
** `PAAS_STAGE_API_URL`
** `PAAS_PROD_API_URL`
* Put `/var/run/secrets/kubernetes.io/serviceaccount/ca.crt` data here
** `PAAS_TEST_CA_PATH`
** `PAAS_STAGE_CA_PATH`
** `PAAS_PROD_CA_PATH`
* Uncheck the `Kubernetes Minikube` value
* Clear the following vars
** `PAAS_TEST_CLIENT_CERT_PATH`
** `PAAS_STAGE_CLIENT_CERT_PATH`
** `PAAS_PROD_CLIENT_CERT_PATH`
** `PAAS_TEST_CLIENT_KEY_PATH`
** `PAAS_STAGE_CLIENT_KEY_PATH`
** `PAAS_PROD_CLIENT_KEY_PATH`
* Set `/var/run/secrets/kubernetes.io/serviceaccount/token` value to these vars
** `PAAS_TEST_CLIENT_TOKEN_PATH`
** `PAAS_STAGE_CLIENT_TOKEN_PATH`
** `PAAS_STAGE_CLIENT_TOKEN_PATH`
* Set the cluster name to these vars (you can get it by calling `kubectl config current-context`)
** `PAAS_TEST_CLUSTER_NAME`
** `PAAS_STAGE_CLUSTER_NAME`
** `PAAS_PROD_CLUSTER_NAME`
* Set the system name to these vars (you can get it by calling `kubectl config current-context`)
** `PAAS_TEST_SYSTEM_NAME`
** `PAAS_STAGE_SYSTEM_NAME`
** `PAAS_PROD_SYSTEM_NAME`
* Update the `DOCKER_EMAIL` property with your email
* Update the `DOCKER_REGISTRY_ORGANIZATION` with your Docker organization name
* If you don't want to upload the images to DockerHub update  `DOCKER_REGISTRY_URL`

image::{jenkins-root-docs}/pks_seed.png[caption="Example of a filled out seed job"]

- Run the pipeline
// remove::end[K8S]

== Jenkins FAQ

Below you can find the answers to most frequently asked questions.

[[jenkins_faq]]
=== Pipeline version contains ${PIPELINE_VERSION}

You can check the Jenkins logs and you'll see

[source,bash]
----
WARNING: Skipped parameter `PIPELINE_VERSION` as it is undefined on `jenkins-pipeline-sample-build`.
	Set `-Dhudson.model.ParametersAction.keepUndefinedParameters`=true to allow undefined parameters
	to be injected as environment variables or
	`-Dhudson.model.ParametersAction.safeParameters=[comma-separated list]`
	to whitelist specific parameter names, even though it represents a security breach
----

To fix it you have to do exactly what the warning suggests... Also ensure that the `Groovy token macro processing`
checkbox is set.

=== Pipeline version is not passed to the build

You can see that the Jenkins version is properly set but in the build version is still snapshot and
the `echo "${PIPELINE_VERSION}"` doesn't print anything.

You can check the Jenkins logs and you'll see

[source,bash]
----
WARNING: Skipped parameter `PIPELINE_VERSION` as it is undefined on `jenkins-pipeline-sample-build`.
	Set `-Dhudson.model.ParametersAction.keepUndefinedParameters`=true to allow undefined parameters
	to be injected as environment variables or
	`-Dhudson.model.ParametersAction.safeParameters=[comma-separated list]`
	to whitelist specific parameter names, even though it represents a security breach
----

To fix it you have to do exactly what the warning suggests...

=== The build times out with `pipeline.sh` info

Docker compose, docker compose, docker compose... The problem is that for some reason, only in Docker, the execution of
Java hangs. But it hangs randomly and only the first time you try to execute the pipeline.

The solution to this is to run the pipeline again. If once it suddenly, magically passes then
it will pass for any subsequent build.

Another thing that you can try is to run it with plain Docker. Maybe that will help.

=== Can I use the pipeline for some other repos?

Sure! you can pass `REPOS` variable with comma separated list of
`project_name$project_url` format. If you don't provide the PROJECT_NAME the
repo name will be extracted and used as the name of the project.

E.g. for `REPOS` equal to:

`https://github.com/spring-cloud-samples/github-analytics,https://github.com/spring-cloud-samples/github-webhook`

will result in the creation of pipelines with root names `github-analytics` and `github-webhook`.

E.g. for `REPOS` equal to:

`foo$https://github.com/spring-cloud-samples/github-analytics,bar$https://github.com/spring-cloud-samples/atom-feed`

will result in the creation of pipelines with root names `foo` for `github-analytics`
and `bar` for `github-webhook`.

=== Will this work for ANY project out of the box?

Not really. This is an `opinionated pipeline` that's why we took some
opinionated decisions like:

- usage of Spring Cloud, Spring Cloud Contract Stub Runner and Spring Cloud Eureka
- application deployment to Cloud Foundry
- For Maven:
    * usage of Maven Wrapper
    * artifacts deployment by `./mvnw clean deploy`
    * `stubrunner.ids` property to retrieve list of collaborators for which stubs should be downloaded
    * running smoke tests on a deployed app via the `smoke` Maven profile
    * running end to end tests on a deployed app via the `e2e` Maven profile
- For Gradle (in the `github-analytics` application check the `gradle/pipeline.gradle` file):
    * usage of Gradlew Wrapper
    * `deploy` task for artifacts deployment
    * running smoke tests on a deployed app via the `smoke` task
    * running end to end tests on a deployed app via the `e2e` task
    * `groupId` task to retrieve group id
    * `artifactId` task to retrieve artifact id
    * `currentVersion` task to retrieve the current version
    * `stubIds` task to retrieve list of collaborators for which stubs should be downloaded

This is the initial approach that can be easily changed in the future.

=== Can I modify this to reuse in my project?

Sure! It's open-source! The important thing is that the core part of the logic is written
in Bash scripts. That way, in the majority of cases, you could change only the bash
scripts without changing the whole pipeline.

=== The rollback step fails due to missing JAR ?!

[[jenkins_tags]] You must have pushed some tags and have removed the Artifactory volume that
contained them. To fix this, just remove the tags

[source,bash]
----
git tag -l | xargs -n 1 git push --delete origin
----

=== I want to provide a different JDK version

- by default we assume that you have jdk with id `jdk8` configured
- if you want a different one just override `JDK_VERSION` env var and point to the proper one

TIP: The docker image comes in with Java installed at `/usr/lib/jvm/java-8-openjdk-amd64`.
You can go to `Global Tools` and create a JDK with `jdk8` id and JAVA_HOME
 pointing to `/usr/lib/jvm/java-8-openjdk-amd64`

To change the default one just follow these steps:

{nbsp}
{nbsp}

image::{jenkins-root-docs}/manage_jenkins.png[caption="Step 1: ", title="Click 'Manage Jenkins'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/global_tool.png[caption="Step 2: ", title="Click 'Global Tool'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/jdk_installation.png[caption="Step 3: ", title="Click 'JDK Installations'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/jdk.png[caption="Step 4: ", title="Fill out JDK Installation with path to your JDK"]

{nbsp}
{nbsp}

And that's it!

[[groovy-token-macro]]
=== Enable Groovy Token Macro Processing

With scripted that but if you needed to this manually then this is how to do it:

{nbsp}
{nbsp}

image::{jenkins-root-docs}/manage_jenkins.png[caption="Step 1: ", title="Click 'Manage Jenkins'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/configure_system.png[caption="Step 2: ", title="Click 'Configure System'"]

{nbsp}
{nbsp}

image::{jenkins-root-docs}/groovy_token.png[caption="Step 3: ", title="Click 'Allow token macro processing'"]

=== I want deployment to stage and prod be automatic

No problem, just set the property / env var to true

- `AUTO_DEPLOY_TO_STAGE` to automatically deploy to stage
- `AUTO_DEPLOY_TO_PROD` to automatically deploy to prod

=== I don't want to test API compativility

No problem, just set the `API_COMPATIBILITY_STEP_REQUIRED` env variable
to `false` and rerun the seed (you can pick it from the seed
job's properties too).

=== I can't tag the repo!

When you get sth like this:

[source,bash]
----
19:01:44 stderr: remote: Invalid username or password.
19:01:44 fatal: Authentication failed for 'https://github.com/marcingrzejszczak/github-webhook/'
19:01:44
19:01:44 	at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandIn(CliGitAPIImpl.java:1740)
19:01:44 	at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.launchCommandWithCredentials(CliGitAPIImpl.java:1476)
19:01:44 	at org.jenkinsci.plugins.gitclient.CliGitAPIImpl.access$300(CliGitAPIImpl.java:63)
19:01:44 	at org.jenkinsci.plugins.gitclient.CliGitAPIImpl$8.execute(CliGitAPIImpl.java:1816)
19:01:44 	at hudson.plugins.git.GitPublisher.perform(GitPublisher.java:295)
19:01:44 	at hudson.tasks.BuildStepMonitor$3.perform(BuildStepMonitor.java:45)
19:01:44 	at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:779)
19:01:44 	at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:720)
19:01:44 	at hudson.model.Build$BuildExecution.post2(Build.java:185)
19:01:44 	at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:665)
19:01:44 	at hudson.model.Run.execute(Run.java:1745)
19:01:44 	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:43)
19:01:44 	at hudson.model.ResourceController.execute(ResourceController.java:98)
19:01:44 	at hudson.model.Executor.run(Executor.java:404)
----

most likely you've passed a wrong password. Check the <<jenkins_credentials,credentials>> section
on how to update your credentials.

=== I'm unauthorized to deploy infrastructure jars

Most likely you've forgotten to update your local `settings.xml` with the Artifactory's
setup. Check out <<jenkins_settings,this section of the docs and update your `settings.xml`>>.

=== Signing Artifacts

In some cases it may be required that when performing a release that the artifacts be signed
before pushing them to the repository.
To do this you will need to import your GPG keys into the Docker image running Jenkins.
This can be done by placing a file called `public.key` containing your public key
and a file called `private.key` containing your private key in the `seed` directory.
These keys will be imported by the `init.groovy` script that is run when Jenkins starts.

=== Using SSH keys for git

The seed job checks if an env variable `GIT_USE_SSH_KEY` is set to `true`. If that's the case
then env variable `GIT_SSH_CREDENTIAL_ID` will be chosen as the one that contains the
id of the credential that contains SSH private key. By default `GIT_CREDENTIAL_ID` will be picked
as the one that contains username and password to connect to git.

You can set these values in the seed job by filling out the form / toggling a checkbox.

=== Deploy to stage fails and doesn't redeploy a service (Kubernetes)

There can be a number of reason but remember that for stage we
assume that a sequence of manual steps need to be performed. We don't
redeploy any existing services cause most likely you deliberately
have set it up in that way or the other. If in the logs of your application
you can see that you can't connect to a service, first ensure that
the service is forwarding traffic to a pod. Next if that's not the case
please delete the service and re-run the step in the pipeline. That way
Spring Cloud Pipelines will redeploy the service and the underlying pods.

=== I ran out of resources!! (Cloud Foundry)

[jenkins-cf-resources]] When deploying the app to stage or prod you can get an exception `Insufficient resources`. The way to
 solve it is to kill some apps from test / stage env. To achieve that just call

[source,bash]
----
cf target -o pcfdev-org -s pcfdev-test
cf stop github-webhook
cf stop github-eureka
cf stop stubrunner
----

You can also execute `./tools/cf-helper.sh kill-all-apps` that will remove all demo-related apps
deployed to PCF Dev.

=== Deploying to test / stage / prod fails - error finding space (Cloud Foundry)

If you receive a similar exception:

[source,bash]
----
20:26:18 API endpoint:   https://api.local.pcfdev.io (API version: 2.58.0)
20:26:18 User:           user
20:26:18 Org:            pcfdev-org
20:26:18 Space:          No space targeted, use 'cf target -s SPACE'
20:26:18 FAILED
20:26:18 Error finding space pcfdev-test
20:26:18 Space pcfdev-test not found
----

It means that you've forgotten to <<jenkins_pcfdev,create the spaces>> in your PCF Dev installation.

=== The route is already in use (Cloud Foundry)

If you play around with Jenkins / Concourse you might end up with the routes occupied

[source,bash]
----
Using route github-webhook-test.local.pcfdev.io
Binding github-webhook-test.local.pcfdev.io to github-webhook...
FAILED
The route github-webhook-test.local.pcfdev.io is already in use.
----

Just delete the routes

[source,bash]
----
yes | cf delete-route local.pcfdev.io -n github-webhook-test
yes | cf delete-route local.pcfdev.io -n github-eureka-test
yes | cf delete-route local.pcfdev.io -n stubrunner-test
yes | cf delete-route local.pcfdev.io -n github-webhook-stage
yes | cf delete-route local.pcfdev.io -n github-eureka-stage
yes | cf delete-route local.pcfdev.io -n github-webhook-prod
yes | cf delete-route local.pcfdev.io -n github-eureka-prod
----

You can also execute the `./tools/cf-helper.sh delete-routes`

=== How to execute helper scripts against a real CF instance I'm logged into (Cloud Foundry)

Assuming that you're already logged into the cluster it's enough to run the
helper script with the `REUSE_CF_LOGIN=true` env variable. Example:

```bash
REUSE_CF_LOGIN=true ./tools/cf-helper.sh setup-prod-infra
```

This script will create the mysql db, rabbit mq service, download and deploy Eureka
to the space and organization you're logged into.